{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第13章の章末演習問題\n",
    "※ ここではGoogle Colaraboratoryでの実行を想定しています。\n",
    "\n",
    "※ Google Colaraboratoryでbashコマンドを実行するには、命令の前に!をつけます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1] 分類モデルのオーギュメンテーションを、本章と同様に個別のモデルとして実装してください"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この問題では12章の分類モデルを使用します（p2ch13_exercise）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （a）実装では何らかを妥協しスキップする必要がありましたか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CPUで行っていたオーギュメンテーションをスキップする必要があります"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （b）訓練速度はどう変わりましたか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回の分類モデルは、比較的シンプルかつ前処理もそこまで複雑ではないので、GPUで前処理を行っても訓練速度はほとんど変わりません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-17 08:43:58,402 INFO     pid:22963 p2ch13_exercise.training:148:initModel Using CUDA; 1 devices.\n"
     ]
    }
   ],
   "source": [
    "# p2ch13-exerciseのファイルを使用します\n",
    "from p2ch13_exercise.training import LunaTrainingApp\n",
    "\n",
    "app = LunaTrainingApp([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-17 08:44:01,810 INFO     pid:22963 p2ch13_exercise.training:219:main Starting LunaTrainingApp, Namespace(augment_flip=True, augment_noise=True, augment_offset=True, augment_rotate=True, augment_scale=True, augmented=False, augmented_gpu=False, balanced=False, batch_size=128, comment='dlwpt', epochs=1, num_workers=8, tb_prefix='p2ch13-exercise')\n",
      "2021-01-17 08:44:03,704 INFO     pid:22963 p2ch13_exercise.dsets:290:__init__ <p2ch13_exercise.dsets.LunaDataset object at 0x7fa561950d30>: 99128 training samples, 98879 neg, 249 pos, unbalanced ratio\n",
      "2021-01-17 08:44:03,714 INFO     pid:22963 p2ch13_exercise.dsets:290:__init__ <p2ch13_exercise.dsets.LunaDataset object at 0x7fa5d95e9748>: 11015 validation samples, 10987 neg, 28 pos, unbalanced ratio\n",
      "2021-01-17 08:44:03,715 INFO     pid:22963 p2ch13_exercise.training:233:main Epoch 1 of 1, 775/87 batches of size 128*1\n",
      "2021-01-17 08:44:03,717 WARNING  pid:22963 util.util:221:enumerateWithEstimate E1 Training ----/775, starting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======train len\n",
      "99128\n",
      "======val len\n",
      "11015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-17 08:44:38,183 INFO     pid:22963 util.util:241:enumerateWithEstimate E1 Training   64/775, done at 2021-01-17 08:50:27, 0:06:17\n",
      "2021-01-17 08:46:14,340 INFO     pid:22963 util.util:241:enumerateWithEstimate E1 Training  256/775, done at 2021-01-17 08:50:32, 0:06:22\n",
      "2021-01-17 08:50:44,905 WARNING  pid:22963 util.util:252:enumerateWithEstimate E1 Training ----/775, done at 2021-01-17 08:50:44\n",
      "2021-01-17 08:50:46,629 INFO     pid:22963 p2ch13_exercise.training:342:logMetrics E1 LunaTrainingApp\n",
      "/home/ubuntu/work/deep-learning-with-pytorch-ja/p2ch13_exercise/training.py:379: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  metrics_dict[\"pr/f1_score\"] = 2 * (precision * recall) / (precision + recall)\n",
      "2021-01-17 08:50:46,722 INFO     pid:22963 p2ch13_exercise.training:391:logMetrics E1 trn      0.0306 loss,  99.6% correct, 0.0000 precision, 0.0000 recall, nan f1 score\n",
      "2021-01-17 08:50:46,722 INFO     pid:22963 p2ch13_exercise.training:403:logMetrics E1 trn_neg  0.0044 loss,  99.9% correct (98779 of 98879)\n",
      "2021-01-17 08:50:46,723 INFO     pid:22963 p2ch13_exercise.training:415:logMetrics E1 trn_pos  10.4323 loss,   0.0% correct (0 of 249)\n",
      "2021-01-17 08:50:46,765 WARNING  pid:22963 util.util:221:enumerateWithEstimate E1 Validation  ----/87, starting\n",
      "2021-01-17 08:50:50,790 INFO     pid:22963 util.util:241:enumerateWithEstimate E1 Validation    16/87, done at 2021-01-17 08:51:12, 0:00:24\n",
      "2021-01-17 08:50:53,751 INFO     pid:22963 util.util:241:enumerateWithEstimate E1 Validation    32/87, done at 2021-01-17 08:51:06, 0:00:18\n",
      "2021-01-17 08:50:59,675 INFO     pid:22963 util.util:241:enumerateWithEstimate E1 Validation    64/87, done at 2021-01-17 08:51:04, 0:00:16\n",
      "2021-01-17 08:51:02,252 WARNING  pid:22963 util.util:252:enumerateWithEstimate E1 Validation  ----/87, done at 2021-01-17 08:51:02\n",
      "2021-01-17 08:51:03,311 INFO     pid:22963 p2ch13_exercise.training:342:logMetrics E1 LunaTrainingApp\n",
      "/home/ubuntu/work/deep-learning-with-pytorch-ja/p2ch13_exercise/training.py:373: RuntimeWarning: invalid value encountered in true_divide\n",
      "  truePos_count + falsePos_count\n",
      "2021-01-17 08:51:03,313 INFO     pid:22963 p2ch13_exercise.training:391:logMetrics E1 val      0.0183 loss,  99.7% correct, nan precision, 0.0000 recall, nan f1 score\n",
      "2021-01-17 08:51:03,313 INFO     pid:22963 p2ch13_exercise.training:403:logMetrics E1 val_neg  0.0012 loss, 100.0% correct (10987 of 10987)\n",
      "2021-01-17 08:51:03,314 INFO     pid:22963 p2ch13_exercise.training:415:logMetrics E1 val_pos  6.7466 loss,   0.0% correct (0 of 28)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 19s, sys: 2min 22s, total: 6min 41s\n",
      "Wall time: 7min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "app.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-17 08:54:45,061 INFO     pid:22963 p2ch13_exercise.training:148:initModel Using CUDA; 1 devices.\n",
      "2021-01-17 08:54:45,066 INFO     pid:22963 p2ch13_exercise.training:219:main Starting LunaTrainingApp, Namespace(augment_flip=True, augment_noise=True, augment_offset=True, augment_rotate=True, augment_scale=True, augmented=False, augmented_gpu=True, balanced=False, batch_size=128, comment='dlwpt', epochs=1, num_workers=8, tb_prefix='p2ch13-exercise')\n",
      "2021-01-17 08:54:45,155 INFO     pid:22963 p2ch13_exercise.dsets:290:__init__ <p2ch13_exercise.dsets.LunaDataset object at 0x7fa5d9e3c128>: 99128 training samples, 98879 neg, 249 pos, unbalanced ratio\n",
      "2021-01-17 08:54:45,166 INFO     pid:22963 p2ch13_exercise.dsets:290:__init__ <p2ch13_exercise.dsets.LunaDataset object at 0x7fa5dec4d048>: 11015 validation samples, 10987 neg, 28 pos, unbalanced ratio\n",
      "2021-01-17 08:54:45,166 INFO     pid:22963 p2ch13_exercise.training:233:main Epoch 1 of 1, 775/87 batches of size 128*1\n",
      "2021-01-17 08:54:45,167 WARNING  pid:22963 util.util:221:enumerateWithEstimate E1 Training ----/775, starting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======train len\n",
      "99128\n",
      "======val len\n",
      "11015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-17 08:55:18,929 INFO     pid:22963 util.util:241:enumerateWithEstimate E1 Training   64/775, done at 2021-01-17 09:01:19, 0:06:29\n",
      "2021-01-17 08:56:58,943 INFO     pid:22963 util.util:241:enumerateWithEstimate E1 Training  256/775, done at 2021-01-17 09:01:27, 0:06:37\n",
      "2021-01-17 09:01:38,747 WARNING  pid:22963 util.util:252:enumerateWithEstimate E1 Training ----/775, done at 2021-01-17 09:01:38\n",
      "2021-01-17 09:01:38,853 INFO     pid:22963 p2ch13_exercise.training:342:logMetrics E1 LunaTrainingApp\n",
      "2021-01-17 09:01:38,903 INFO     pid:22963 p2ch13_exercise.training:391:logMetrics E1 trn      0.0198 loss,  99.7% correct, 0.0000 precision, 0.0000 recall, nan f1 score\n",
      "2021-01-17 09:01:38,904 INFO     pid:22963 p2ch13_exercise.training:403:logMetrics E1 trn_neg  0.0027 loss, 100.0% correct (98876 of 98879)\n",
      "2021-01-17 09:01:38,905 INFO     pid:22963 p2ch13_exercise.training:415:logMetrics E1 trn_pos  6.8212 loss,   0.0% correct (0 of 249)\n",
      "2021-01-17 09:01:38,947 WARNING  pid:22963 util.util:221:enumerateWithEstimate E1 Validation  ----/87, starting\n",
      "2021-01-17 09:01:43,067 INFO     pid:22963 util.util:241:enumerateWithEstimate E1 Validation    16/87, done at 2021-01-17 09:02:05, 0:00:25\n",
      "2021-01-17 09:01:46,068 INFO     pid:22963 util.util:241:enumerateWithEstimate E1 Validation    32/87, done at 2021-01-17 09:01:58, 0:00:18\n",
      "2021-01-17 09:01:52,524 INFO     pid:22963 util.util:241:enumerateWithEstimate E1 Validation    64/87, done at 2021-01-17 09:01:57, 0:00:17\n",
      "2021-01-17 09:01:55,294 WARNING  pid:22963 util.util:252:enumerateWithEstimate E1 Validation  ----/87, done at 2021-01-17 09:01:55\n",
      "2021-01-17 09:01:56,256 INFO     pid:22963 p2ch13_exercise.training:342:logMetrics E1 LunaTrainingApp\n",
      "2021-01-17 09:01:56,258 INFO     pid:22963 p2ch13_exercise.training:391:logMetrics E1 val      0.0179 loss,  99.7% correct, nan precision, 0.0000 recall, nan f1 score\n",
      "2021-01-17 09:01:56,258 INFO     pid:22963 p2ch13_exercise.training:403:logMetrics E1 val_neg  0.0036 loss, 100.0% correct (10987 of 10987)\n",
      "2021-01-17 09:01:56,259 INFO     pid:22963 p2ch13_exercise.training:415:logMetrics E1 val_pos  5.6315 loss,   0.0% correct (0 of 28)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 59s, sys: 6.79 s, total: 7min 6s\n",
      "Wall time: 7min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "app = LunaTrainingApp([\"--augmented-gpu\"])\n",
    "app.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2] セグメンテーションのDatasetの実装を変更して訓練、検証、テストセットの3つに分割できるようにしてください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p2ch13_exercise2のファイルを使用します\n",
    "from p2ch13_exercise2.training import SegmentationTrainingApp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （a）テストセットにはデータのどれくらいの割合を使いましたか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回は、訓練：（検証＋テスト）を8:2に分けたのち、検証とテストををそれぞれ1：1になるように分けました。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （b）テストセットに対する性能と検証セットに対する性能は同程度でしたか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ほぼ同程度となる\n",
    "（※ 実行条件による）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-24 11:34:40,653 INFO     pid:11667 p2ch13_exercise2.training:165:initModel Using CUDA; 1 devices.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e25f0ebb3140>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mapp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSegmentationTrainingApp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/deep-learning-with-pytorch-ja/p2ch13_exercise2/training.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sys_argv)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_cuda\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msegmentation_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugmentation_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/deep-learning-with-pytorch-ja/p2ch13_exercise2/training.py\u001b[0m in \u001b[0;36minitModel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0msegmentation_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegmentation_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0maugmentation_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maugmentation_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0msegmentation_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegmentation_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m             \u001b[0maugmentation_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maugmentation_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36_pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_backward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36_pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36_pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    221\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36_pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "app = SegmentationTrainingApp([])\n",
    "app.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = SegmentationTrainingApp([\"--doTest\"])\n",
    "app.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （c）訓練サンプル数を減らすと、訓練結果はどの程度悪くなりましたか。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "（a）の割合で分けた場合、訓練結果のlossは0.02、tpは0.3%ほど劣化した。\\\n",
    "（分ける割合によって値は変わります）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [3] 結節・非結節を見分けるだけでなく、悪性結節が良性結節かも見分けるセグメンテーションモデルを作成してください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from random import shuffle\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from operator import attrgetter\n",
    "import scipy.ndimage.measurements as measurements\n",
    "import scipy.ndimage.morphology as morphology\n",
    "from p2ch13_exercise3.model import UNetWrapper, SegmentationAugmentation\n",
    "from p2ch13_exercise3.dsets import getCandidateInfoList, getCt, TrainingLuna2dSegmentationDataset, CandidateInfoTuple, Luna2dSegmentationDataset\n",
    "from util.util import xyz2irc, irc2xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=32\n",
    "N_EPOCHS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data-unversioned/part2/luna配下に存在するデータのみを今回の処理の対象にする。\n",
    "series_uid = glob.glob('data-unversioned/part2/luna/subset0/*.mhd')\n",
    "series_uid = list(map(lambda x: x[x.rfind('/')+1:-4], series_uid))\n",
    "segmentation_train_series_uid = series_uid[0:15]\n",
    "segmentation_valid_series_uid = [series_uid[15:20]]\n",
    "classification_train_series_uid = series_uid[20:35]\n",
    "classification_valid_series_uid = series_uid[35:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataloader(series_uid:str)->torch.utils.data.DataLoader:\n",
    "    ds = TrainingLuna2dSegmentationDataset(\n",
    "            val_stride=0,\n",
    "            isValSet_bool=False,\n",
    "            contextSlices_count=3,\n",
    "            series_uid=series_uid\n",
    "    )\n",
    "    return  torch.utils.data.DataLoader(\n",
    "        ds,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_workers=8,\n",
    "        pin_memory=False)\n",
    "\n",
    "def doTraining(model:torch.nn.Module, optimizer:torch.optim.Optimizer, epoch_ndx:int, train_dl:torch.utils.data.DataLoader)->torch.Tensor:\n",
    "        trnMetrics_g = torch.zeros(METRICS_SIZE, len(train_dl.dataset), device='cuda')\n",
    "        model.train()\n",
    "        train_dl.dataset.shuffleSamples()\n",
    "        bar = tqdm(train_dl)\n",
    "        for batch_ndx, batch_tup in enumerate(bar):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss_var = computeBatchLoss(model, batch_ndx, batch_tup, train_dl.batch_size, trnMetrics_g)\n",
    "            loss_var.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            bar.set_description('loss: %.5f' % loss_var.item())\n",
    "\n",
    "        return trnMetrics_g.to('cpu')\n",
    "\n",
    "def doValidation(model:torch.nn.Module, epoch_ndx, val_dl)->torch.Tensor:\n",
    "    bar = tqdm(val_dl)\n",
    "    with torch.no_grad():\n",
    "        valMetrics_g = torch.zeros(METRICS_SIZE, len(val_dl.dataset), device='cuda')\n",
    "        model.eval()\n",
    "\n",
    "        for batch_ndx, batch_tup in enumerate(bar):\n",
    "            computeBatchLoss(model, batch_ndx, batch_tup, val_dl.batch_size, valMetrics_g)\n",
    "\n",
    "    return valMetrics_g.to('cpu')\n",
    "\n",
    "def computeBatchLoss(segmentation_model:torch.nn.Module, batch_ndx:int, batch_tup:tuple, batch_size:int, metrics_g:torch.Tensor,\n",
    "                        classificationThreshold:float=0.5)->torch.Tensor:\n",
    "    input_t, label_t, series_list, _slice_ndx_list = batch_tup\n",
    "\n",
    "    input_g = input_t.to('cuda', non_blocking=True)\n",
    "    label_g = label_t.to('cuda', non_blocking=True)\n",
    "\n",
    "    prediction_g = segmentation_model(input_g)\n",
    "\n",
    "    diceLoss_g = diceLoss(prediction_g, label_g)\n",
    "    fnLoss_g = diceLoss(prediction_g * label_g, label_g)\n",
    "\n",
    "    start_ndx = batch_ndx * batch_size\n",
    "    end_ndx = start_ndx + input_t.size(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predictionBool_g = (prediction_g[:, 0:1]\n",
    "                            > classificationThreshold).to(torch.float32)\n",
    "\n",
    "        tp = (     predictionBool_g *  label_g).sum(dim=[1,2,3])\n",
    "        fn = ((1 - predictionBool_g) *  label_g).sum(dim=[1,2,3])\n",
    "        fp = (     predictionBool_g * (~label_g)).sum(dim=[1,2,3])\n",
    "\n",
    "        metrics_g[METRICS_LOSS_NDX, start_ndx:end_ndx] = diceLoss_g\n",
    "        metrics_g[METRICS_TP_NDX, start_ndx:end_ndx] = tp\n",
    "        metrics_g[METRICS_FN_NDX, start_ndx:end_ndx] = fn\n",
    "        metrics_g[METRICS_FP_NDX, start_ndx:end_ndx] = fp\n",
    "\n",
    "    return diceLoss_g.mean() + fnLoss_g.mean() * 8\n",
    "\n",
    "def diceLoss(prediction_g, label_g, epsilon=1):\n",
    "    diceLabel_g = label_g.sum(dim=[1,2,3])\n",
    "    dicePrediction_g = prediction_g.sum(dim=[1,2,3])\n",
    "    diceCorrect_g = (prediction_g * label_g).sum(dim=[1,2,3])\n",
    "\n",
    "    diceRatio_g = (2 * diceCorrect_g + epsilon) / (dicePrediction_g + diceLabel_g + epsilon)\n",
    "\n",
    "    return 1 - diceRatio_g\n",
    "\n",
    "def logMetrics(epoch_ndx, mode_str, metrics_t):\n",
    "\n",
    "    metrics_a = metrics_t.detach().numpy()\n",
    "    sum_a = metrics_a.sum(axis=1)\n",
    "    assert np.isfinite(metrics_a).all()\n",
    "\n",
    "    allLabel_count = sum_a[METRICS_TP_NDX] + sum_a[METRICS_FN_NDX]\n",
    "\n",
    "    metrics_dict = {}\n",
    "    metrics_dict['loss/all'] = metrics_a[METRICS_LOSS_NDX].mean()\n",
    "    metrics_dict['percent_all/tp'] = sum_a[METRICS_TP_NDX] / (allLabel_count or 1) * 100\n",
    "    metrics_dict['percent_all/fn'] = sum_a[METRICS_FN_NDX] / (allLabel_count or 1) * 100\n",
    "    metrics_dict['percent_all/fp'] = sum_a[METRICS_FP_NDX] / (allLabel_count or 1) * 100\n",
    "\n",
    "\n",
    "    precision = metrics_dict['pr/precision'] = sum_a[METRICS_TP_NDX] / ((sum_a[METRICS_TP_NDX] + sum_a[METRICS_FP_NDX]) or 1)\n",
    "    recall    = metrics_dict['pr/recall']    = sum_a[METRICS_TP_NDX] / ((sum_a[METRICS_TP_NDX] + sum_a[METRICS_FN_NDX]) or 1)\n",
    "\n",
    "    metrics_dict['pr/f1_score'] = 2 * (precision * recall) / ((precision + recall) or 1)\n",
    "    return metrics_dict['pr/recall']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-27 07:19:19,969 INFO     pid:30457 p2ch13_exercise3.dsets:305:__init__ <p2ch13_exercise3.dsets.TrainingLuna2dSegmentationDataset object at 0x7f05ed799c88>: 15 training series, 156 slices, 18 nodules\n"
     ]
    }
   ],
   "source": [
    "train_dl = getDataloader(series_uid=segmentation_train_series_uid)\n",
    "#valid_dl = getDataloader(series_uid=segmentation_valid_series_uid)\n",
    "segmentation_model = UNetWrapper(\n",
    "            in_channels=7,\n",
    "            n_classes=3,\n",
    "            depth=3,\n",
    "            wf=4,\n",
    "            padding=True,\n",
    "            batch_norm=True,\n",
    "            up_mode='upconv',\n",
    "        )\n",
    "\n",
    "\n",
    "ct_t, pos_t, series_uid, slice_ndx = next(iter(train_dl))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 64])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#plt.imshow(pos_t[0].permute(1, 2, 0).numpy(), cmap='gray')\n",
    "ct_t[0][0:1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f05e1b8ff60>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(ct_t[0][0:1].permute(1, 2, 0).numpy(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_model=segmentation_model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: -4.48522: 100%|██████████| 9375/9375 [04:24<00:00, 35.51it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'valid_dl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-41d8ff5a9c25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch_ndx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtrnMetrics_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoTraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegmentation_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_ndx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mvalMetrics_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoValidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegmentation_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_ndx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mtrain_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogMetrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_ndx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrnMetrics_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogMetrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_ndx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalMetrics_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'valid_dl' is not defined"
     ]
    }
   ],
   "source": [
    "METRICS_SIZE=10\n",
    "METRICS_LOSS_NDX = 1\n",
    "METRICS_TP_NDX = 7\n",
    "METRICS_FN_NDX = 8\n",
    "METRICS_FP_NDX = 9\n",
    "\n",
    "best_score = 0.0\n",
    "train_scores=[]\n",
    "valid_scores=[]\n",
    "optimizer = torch.optim.Adam(segmentation_model.parameters())\n",
    "early_stopping_count = 0\n",
    "for epoch_ndx in range(1, N_EPOCHS+1):\n",
    "    trnMetrics_t = doTraining(segmentation_model, optimizer, epoch_ndx, train_dl)\n",
    "    #valMetrics_t = doValidation(segmentation_model, epoch_ndx, valid_dl)\n",
    "    train_scores.append(logMetrics(epoch_ndx, 'train', trnMetrics_t))   \n",
    "    score = logMetrics(epoch_ndx, 'val', valMetrics_t)\n",
    "    #valid_scores.append(score) \n",
    "    if score <= best_score:\n",
    "        early_stopping_count += 1\n",
    "    best_score = max(score, best_score)\n",
    "    if early_stopping_count==EARLY_STOPPING:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （a）指標のレポートをどう変えなければなりませんか。画像の出力はどうでしょうか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （b）結果はどうなりましたか。結果は、次の分類ステップを省略できる程の性能でしたか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [4] 64 × 64クロップ画像とスライス全体の両方を使って訓練ができますか"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dsets.pyのgetitem_trainingCrop関数内でクロップとスライス全体がバッチごとに交互に選択されるようにします。\\\n",
    "（注釈[16]にあるように、バッチ内のサンプルは同じサイズである必要がありますが、バッチ間は必ずしも同じテンソルサイズでなくて大丈夫です）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5] LUNA（あるいはLIDC）意外に使えるデータを探してみてください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##省略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
